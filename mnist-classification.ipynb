{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #Pytorch\n",
    "import torch.nn as nn #Pytorch neural network module\n",
    "from torch.optim import SGD #Optimization Algorithms\n",
    "import torch.nn.functional as F #Encodes the dataset\n",
    "from torch.utils.data import Dataset, DataLoader #Used for managing data\n",
    "import torchvision #Various resources for computer vision\n",
    "import numpy as np #Handles high-level math operations\n",
    "import matplotlib.pyplot as plt #Plot data for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vj/rxr6zwfn3rl3x08myxqw9ftw0000gn/T/ipykernel_14299/1099657051.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x,y = torch.load('MNIST/processed/training.pt')\n"
     ]
    }
   ],
   "source": [
    "x,y = torch.load('MNIST/processed/training.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape #x holds 60000 28*28 2D images\n",
    "x[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape # y hold 60000 labels\n",
    "y[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[0].numpy()) #Plots the image at x[0]\n",
    "plt.title(f'The number: {y[0].numpy()}') #Label assiciated with x[0]\n",
    "plt.colorbar() #Colorbar alongside graph\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = torch.tensor([2, 4, 3, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binary representation of the  classes in y_original\n",
    "F.one_hot(y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = F.one_hot(y, num_classes=10) #Specify 10 classes in y\n",
    "y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We can look and the output as a PMF\\n    which will later be used when training'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new\n",
    "\"\"\"We can look and the output as a PMF\n",
    "    which will later be used when training\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1,28**2).shape #tranform each image to a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "An abstract class representing a :class:`Dataset`.\n",
      "\n",
      "All datasets that represent a map from keys to data samples should subclass\n",
      "it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      "data sample for a given key. Subclasses could also optionally overwrite\n",
      ":meth:`__len__`, which is expected to return the size of the dataset by many\n",
      ":class:`~torch.utils.data.Sampler` implementations and the default options\n",
      "of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
      "optionally implement :meth:`__getitems__`, for speedup batched samples\n",
      "loading. This method accepts list of indices of samples of batch and returns\n",
      "list of samples.\n",
      "\n",
      ".. note::\n",
      "  :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
      "  sampler that yields integral indices.  To make it work with a map-style\n",
      "  dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/torch/utils/data/dataset.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     IterableDataset, TensorDataset, StackDataset, ConcatDataset, Subset, MapDataPipe, VisionDataset, CTDataset, CTDataset"
     ]
    }
   ],
   "source": [
    "Dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our own class\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, filepath) -> None:\n",
    "        self.x, self.y = torch.load(filepath) #Load data from filepath\n",
    "        self.x = self.x / 255 #Normalize data in x to between 0 and 1\n",
    "        self.y = F.one_hot(self.y, num_classes=10).to(float) #Simply show as 0.0 or 1.0\n",
    "    def __len__(self) -> int:\n",
    "        return self.x.shape[0]#Return the number of images in x\n",
    "    def __getitem__(self, ix):\n",
    "        return self.x[ix], self.y[ix] #Return image and label at ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vj/rxr6zwfn3rl3x08myxqw9ftw0000gn/T/ipykernel_14299/2246059733.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.x, self.y = torch.load(filepath) #Load data from filepath\n"
     ]
    }
   ],
   "source": [
    "train_ds = CTDataset('MNIST/processed/training.pt')\n",
    "test_ds = CTDataset('MNIST/processed/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds) #Using __len__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706, 0.4941, 0.5333,\n",
       "          0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176,\n",
       "          0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333,\n",
       "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9843,\n",
       "          0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588,\n",
       "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137, 0.9686, 0.9451,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137,\n",
       "          0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000, 0.1686, 0.6039,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275, 0.4235, 0.0039,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922, 0.9922, 0.4667,\n",
       "          0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294, 0.9922, 0.9922,\n",
       "          0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.3647, 0.9882,\n",
       "          0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9765,\n",
       "          0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098, 0.7176, 0.9922,\n",
       "          0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922, 0.9922, 0.9922,\n",
       "          0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922, 0.9922, 0.7882,\n",
       "          0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902,\n",
       "          0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.3176, 0.0078,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706, 0.8588,\n",
       "          0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314,\n",
       "          0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000]]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=torch.float64))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0] #Using __getitem__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Dataloader class to  specify a `bath_size` when training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0m_T_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcollate_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0m_T\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdrop_last\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mworker_init_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmultiprocessing_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprefetch_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpersistent_workers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpin_memory_device\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
      "\n",
      "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "iterable-style datasets with single- or multi-process loading, customizing\n",
      "loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "Args:\n",
      "    dataset (Dataset): dataset from which to load the data.\n",
      "    batch_size (int, optional): how many samples per batch to load\n",
      "        (default: ``1``).\n",
      "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "        at every epoch (default: ``False``).\n",
      "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "        returns a batch of indices at a time. Mutually exclusive with\n",
      "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "        and :attr:`drop_last`.\n",
      "    num_workers (int, optional): how many subprocesses to use for data\n",
      "        loading. ``0`` means that the data will be loaded in the main process.\n",
      "        (default: ``0``)\n",
      "    collate_fn (Callable, optional): merges a list of samples to form a\n",
      "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "        map-style dataset.\n",
      "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "        into device/CUDA pinned memory before returning them.  If your data elements\n",
      "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "        see the example below.\n",
      "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "        the size of dataset is not divisible by the batch size, then the last batch\n",
      "        will be smaller. (default: ``False``)\n",
      "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "        from workers. Should always be non-negative. (default: ``0``)\n",
      "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "        input, after seeding and before data loading. (default: ``None``)\n",
      "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
      "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
      "        be used. (default: ``None``)\n",
      "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
      "        ``base_seed`` for workers. (default: ``None``)\n",
      "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      "        in advance by each worker. ``2`` means there will be a total of\n",
      "        2 * num_workers batches prefetched across all workers. (default value depends\n",
      "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      "        Otherwise, if value of ``num_workers > 0`` default is ``2``).\n",
      "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
      "        the worker processes after a dataset has been consumed once. This allows to\n",
      "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
      "        ``True``.\n",
      "\n",
      "\n",
      ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "             cannot be an unpicklable object, e.g., a lambda function. See\n",
      "             :ref:`multiprocessing-best-practices` on more details related\n",
      "             to multiprocessing in PyTorch.\n",
      "\n",
      ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "             loading to avoid duplicate data.\n",
      "\n",
      "             However, if sharding results in multiple workers having incomplete last batches,\n",
      "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "             cases in general.\n",
      "\n",
      "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "             `Multi-process data loading`_.\n",
      "\n",
      ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "\n",
      ".. _multiprocessing context:\n",
      "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.pyenv/versions/3.11.11/lib/python3.11/site-packages/torch/utils/data/dataloader.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing dataset of 60000 elements to 12000 batches of 5 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 28, 28])\n",
      "torch.Size([5, 10])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dl:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl) #Number of batches held by train_dl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
